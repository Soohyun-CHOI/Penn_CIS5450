{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1AmlPYxdkrDLGlVIm7SEJQmANOhWUjE4y","timestamp":1694627508178}],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"MHT1ypO7StBy"},"source":["# Recitation 3 - Integration and Visualization"]},{"cell_type":"markdown","source":["In this notebook, we will be using the BBC GoodFoods dataset which will give us some hands-on practice of data integration and visualization. The dataset is created by Arth Talati by scraping https://www.bbc.co.uk/food.\n","\n"],"metadata":{"id":"B5DBf84x093_"}},{"cell_type":"markdown","source":["# Importing Packages\n","\n","One of the reasons why Python is an extremely useful language is due to the wide array of packages avaliable.\n","\n","These are some of the packages that we will be using within this notebook:\n","1. `pandas`: the bread and butter package that you will get to know very well throughout this course\n","2. `seaborn`: simple, yet aesthetic data visualization\n","3. `plotly`: interactive data visualization\n","4. `pickle`: serializing and deserializing python object structures\n","\n","Other notable packages are `numpy` (array manipulation) , `matplotlib` (data visualization), and `scikit-learn` (machine learning)"],"metadata":{"id":"Dw38QT_-185P"}},{"cell_type":"markdown","metadata":{"id":"pVhONQ0jH_tJ"},"source":["# 1. Data Import"]},{"cell_type":"code","metadata":{"id":"BiMjrS-YoR1r"},"source":["# Basic imports\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import plotly.express as px\n","import plotly as py\n","import plotly.graph_objs as go\n","import pickle\n","\n","# Mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Run the following cell to load the dataset"],"metadata":{"id":"nKp05_Om2qVu"}},{"cell_type":"code","metadata":{"id":"axpv7YR3Sswy"},"source":["# Loading the dataset from the google drive\n","file_path = r\"/content/sample_data/bbc_df.data\"\n","with open(file_path, 'rb') as filehandle:\n","    # read the data as binary data stream\n","    bbc_df = pickle.load(filehandle)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's see what our data looks like"],"metadata":{"id":"-NSsPMxK3Uox"}},{"cell_type":"code","metadata":{"id":"kxpmLl71O1ix"},"source":["# Displaying first 5 rows of the dataset\n","bbc_df.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O8kv5KIFJCT-"},"source":["# 2. Data Exploration"]},{"cell_type":"markdown","source":["Before we can implement algorithms or derive useful insights from the data, we need to understand our data. So let us begin our data exploration!"],"metadata":{"id":"Ux_2J5pEMw7p"}},{"cell_type":"markdown","source":["The describe() function will help us to get some important statistics like mean, std, min, max etc. to undertand the distribution of our data."],"metadata":{"id":"9lE3T7Jc34-w"}},{"cell_type":"code","metadata":{"id":"b1JeQK_6Jpfk"},"source":["#TODO: Get descriptive statistics and distributions for each column\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can use dtypes to get the datatype of each column in the dataframe."],"metadata":{"id":"EFimEXZQ4Nf3"}},{"cell_type":"code","metadata":{"id":"IcDhR6opJGRW"},"source":["#TODO: Inspect the types of each column in a dataframe\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The is.na() function is used to find out if there are null values in the dataset. This will be useful when we deal with real world data and need to handle missing values. The following code will provide the null value distribution across columns"],"metadata":{"id":"eJS81H_o4hbs"}},{"cell_type":"code","metadata":{"id":"r7aQar2h1mKs"},"source":["# TODO: Find the total number of null values in each column\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, let's plot some histograms to get a better sense of our data!"],"metadata":{"id":"JTNdY0uk4yXA"}},{"cell_type":"markdown","source":["Run the following cell to plot a histogram for the column `rating` in the dataset. This will give us a visual representation of the disribution of values in `rating`"],"metadata":{"id":"E0nUkiAM5Ju7"}},{"cell_type":"code","metadata":{"id":"b2c6NtMoLmJ6"},"source":["#TODO: Plotting a histogram using the values of the column `rating`\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FNyvz_llL2Ea"},"source":["#TODO: Plot a histogram for the column `serves`\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XISpob0ZKdsu"},"source":["#TODO: Plot a histogram for the column `prep_time`. Also specify the number of bins as 10\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dealing with Lists and List comprehension"],"metadata":{"id":"MknMpEatTpzO"}},{"cell_type":"markdown","source":["Lists are a built-in datatype to store colections of data in Python. While for loops can be used to perform functions on a list, in this section, we will explore list comprehension. This is much faster and more computationally efficient as compared to for loops"],"metadata":{"id":"spYKKfKoTzMC"}},{"cell_type":"markdown","source":["IMPORTANT: We highly encourage you to familiarize yourself with list comprehension as it is an essential tool for this course"],"metadata":{"id":"0HO3OJj7T0M2"}},{"cell_type":"markdown","source":["Let's start with a few examples -"],"metadata":{"id":"6iNZ-QfMT4cH"}},{"cell_type":"code","source":["# List Comprehension Example:\n","\n","#1D list\n","\n","\n","# Using for loops\n","\n"],"metadata":{"id":"JqUS5JYuT80c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2D List\n"],"metadata":{"id":"SLAxt8Z7UAfv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Back to our data! Let's inspect the values we have in our column `diet_types`\n"],"metadata":{"id":"g_eVufi9UD7_"}},{"cell_type":"code","source":["# Looking at the values in the column `diet_types`\n"],"metadata":{"id":"TyyZlKHzUJ-G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can see that the data in columns is in the form of lists. Now, let's use list comprehension in our dataset to get a set of unique values from the column `diet_types`"],"metadata":{"id":"fhPu0RN1UV8d"}},{"cell_type":"code","source":["# TODO: Replacing nan with NO_TAG\n"],"metadata":{"id":"42Oy1BehUXJn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: Flatten the list of lists to a single list\n","\n","# TODO: Set function takes the unique elements from the list\n"],"metadata":{"id":"f3HrQEuF3HN-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Manipulation\n","\n","In the following section, we will once again review some functions that will be important for Homework 1, specifically:\n","\n","1. `apply()`\n","2. `merge()`\n","3. `group_by()` and `reset_index()`"],"metadata":{"id":"4Qo286twR1fs"}},{"cell_type":"markdown","source":["### 1. Apply"],"metadata":{"id":"EOl5ca-wUsaA"}},{"cell_type":"markdown","source":["Taking a look at the structure of the nutrition column, we see that it is in the form of key-value pairs"],"metadata":{"id":"dFOOgyf2SSsn"}},{"cell_type":"code","source":["# TODO: Inspect a sample observation of `nutrition` column\n"],"metadata":{"id":"MDft9MXWSSRm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's use apply() on our bbc_df to split the nutrition column into individual columns based on keys\n","\n","Note: apply() takes in an axis parameter which details axis to apply the function on. axis=0 will act on all rows in each column, while axis=1 will act on all columns in each row."],"metadata":{"id":"oEZ-DfGLR3N4"}},{"cell_type":"markdown","source":["Now, we will convert the `nutrition` column into a dataframe by applying a series function `pd.Series` to the column!"],"metadata":{"id":"w3P7qra46HP1"}},{"cell_type":"code","metadata":{"id":"DmXW879Fn1Qp"},"source":["# TODO: Make a new df only for data related to nutrition\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M2bQDYHiDovD"},"source":["### Seconds to minutes"]},{"cell_type":"code","metadata":{"id":"GhPGcuY-DtRA"},"source":["# TODO: Cast the column `prep_time` as float\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gvewoYMEEWIy"},"source":["# TODO: Convert column to timedelta format - >  %H:%M:%S\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RZ8JpznZFIaG"},"source":["# TODO: Check the datatype of columns after conversion\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2. Merge\n","Merge is used to join two dataframes with a common id variable. It is also really useful to see intersections between two dataframes - think Venn Diagrams."],"metadata":{"id":"VlIYn7GyUz5B"}},{"cell_type":"markdown","source":["What would happen if we had data in separate dataframes?\n","\n","Let us consider that we have two dataframes which contain the following information:\n","1. cuisines_df: contains the id, title and cuisine\n","2. ratings_df: contains the id and ratings"],"metadata":{"id":"cOkkJGNzVvz0"}},{"cell_type":"code","source":["# TODO: Create cuisines_df which has the columns id, title and cusine\n"],"metadata":{"id":"kGSAWLkaWTiA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: Create ratings_df which has the columns id, rating_of_100\n"],"metadata":{"id":"knLlRmkEWcaw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s722qGeZrYYh"},"source":["\n","Which are the top dishes (rating wise) and what are their ratings?"]},{"cell_type":"code","source":["# TODO: Merge the dataframes cuisines_df and ratings_df to find which dishes have the top ratings\n"],"metadata":{"id":"lpCeCBgxWo2R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Try setting how=left and how=right\n","\n","What do you notice?"],"metadata":{"id":"Vjp5_6hwViQY"}},{"cell_type":"code","source":["# TODO: Implement the above merge operation by setting how=left (call it left_cuisines_df) and how=right (call it right_cuisines_df)\n"],"metadata":{"id":"diAqNq4q3n01"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3. Aggregation\n","\n","In order to get a broader picture of our data, we often want to aggregate values with classic summary statistics such as mean, median, and count.\n","This is especially important when we want to compare different groups within our data.\n","\n","Now that we have a top_cuisines_df that consists of all recipe titles, cuisines and their respective ratings, an interesting metric to look at would be the rating of each cuisine\n","\n","In order to do this in pandas, we must first call the groupby() function and specify the group we want to aggregate on (in this case cuisine) and then call the specific summary statistic function.\n","\n","For example, if we wanted to find the mean of each group we would do the following:\n","\n","df.group_by(group).mean()\n","\n","Let's create a new df, agg_cusines_df that will group our top_cuisines_df by the field cuisine and calculate the mean\n","\n","Notice our use of reset_index()"],"metadata":{"id":"_GCoR1VOW98A"}},{"cell_type":"code","metadata":{"id":"_4sxHELJ_YBo"},"source":["#TODO: Get the average ratings of all cuisines\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now let's try the same question using pandasql\n","\n","pandasql allows you to query pandas DataFrames using SQL syntax"],"metadata":{"id":"IXfO0sADYLHg"}},{"cell_type":"code","metadata":{"id":"EQS6mU1HWuAU"},"source":["!pip install pandasql\n","!pip install sqlalchemy==1.4.46\n","import pandasql as ps #SQL on Pandas Dataframe"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cuisines_df"],"metadata":{"id":"3enHIygQTmqu"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"arbYlTRBVaPn"},"source":["# TODO: Write a SQL query to get the average rating of all cuisines\n","bbc_rating_df = bbc_df[['id', 'rating_of_100']]\n","cus_query = \"\"\"\n","\"\"\"\n","rating_df = ps.sqldf(cus_query, locals())\n","rating_df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Visualization\n","\n","Now, that we have sufficiently explored our data, let's start creating some visualizations!. We will specifically be using `seaborn` and `plotly`.\n","\n","- [seaborn](https://seaborn.pydata.org/) creates relatively aesthetic visualizatons with minimal effort. I like using seaborn for simple, yet informative graphs like barplots, boxplots and line charts and. since the syntax is very straightforward and easy to underst\n","- [plotly](https://plot.ly/python/) is my favorite Python visualization tool as it creates *interactive* visualizations. There are many predefined graph templates avaliable on the website that can be used to create complex visualizations.\n","\n","Throughout this section, remember the following data visualization steps:\n","\n","1. Look at your data\n","2. Identify the message and its components\n","3. Select your chart\n","4. Refine"],"metadata":{"id":"IlTkulB_ZVyx"}},{"cell_type":"code","source":["# Necessary imports\n","import pandas as pd\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly.express as px\n","import plotly as py\n","import plotly.graph_objs as go"],"metadata":{"id":"4Oid4pnvZeX7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Visualization with Seaborn\n","Using seaborn, let’s answer some simple questions:\n","### 1. What is the most common level of difficulty within our set of recipes?\n","To answer this question, the most fitting graph would be a countplot. Let’s use `bbc_df`, let’s make a countplot of the column `difficulty`."],"metadata":{"id":"df1bWf10qJsH"}},{"cell_type":"code","source":["#TODO: Countplot of the column `difficulty`\n"],"metadata":{"id":"7SKUwAfiqKQo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","### 2. How does `prep_time` vary by difficulty?\n","\n","Because `prep_time` is a quantitative variable, it will have numeric properties that relate to its distribution (mean, median, spread, etc.) Thus, things like scatter plots, box plots would be great ways to look at the data.\n","\n","Another effective plot would be a violin plot, which overlays the shape of the overall distribution on top of a standard boxplot.\n","\n","Using the `bbc_df` dataframe that contains all of our data from the dataset, let's compare difficulty scores:"],"metadata":{"id":"_Q3V2MZrqOij"}},{"cell_type":"code","source":["#TODO: violin plot with prep_time and difficulty\n"],"metadata":{"id":"FAnua09vqg2m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Visualization with Plotly\n","With plotly, let’s try to create more layered and complex graphs. These can also be created in seaborn, but plotly’s biggest advantages is that you can interact with the graphs in various ways including zooming, isolating variables, and hovering tool tips. This means that you can afford to iniitally create more complicated visuals as you will have the opportunity to interact and adjust the graph later on."],"metadata":{"id":"mR08V3Auq5GE"}},{"cell_type":"markdown","source":["\n","###1. Grouped Bar Plots\n","One way to “spice” up visualizations is using color to further categorize information. Let’s take advantage of this to compare the different types of genres within our playlists."],"metadata":{"id":"SwOBAf1IrC1N"}},{"cell_type":"code","source":["#TODO: Make a plotly bar plot with prep_time and cuisine\n"],"metadata":{"id":"D60JpSwdrAMM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2. 3D Scatter Plots\n","\n","plotly has a ton of interesting visualization tools, but just because they are interesting, doesn't mean that they are actually meaningful. Would you argue that the 3D scatter plot below is a helpful visual?"],"metadata":{"id":"z2AqIMxirvIt"}},{"cell_type":"code","source":["#TODO: Make a plotly 3d plot with cook_time, prep_time and cuisine\n"],"metadata":{"id":"mkhUc-SkrxHS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3. Side-by-Side Violin Plot\n","\n","We can manipulate our classic violin plot into a side-by-side violin plot to compare distributions of difficulty across different cuisines. What are the pros of this visualization? Cons?"],"metadata":{"id":"1KMyaCZur1re"}},{"cell_type":"code","source":["#TODO: Make a plotly side by side violin plot with difficulty and cuisine as main variables"],"metadata":{"id":"1UNItm0er6JG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4. Radial Plots\n","\n","Radial plots, or spider plots is another way to visualize the magnitudes of data. What are the pros of this visualization? Cons?"],"metadata":{"id":"7ZhIutYisLvI"}},{"cell_type":"code","source":["#TODO: Make a radial plot using cuisine and difficulty\n"],"metadata":{"id":"dcC93JGssYqs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##5. Word Clouds\n","\n","Word Clouds are a great way to view text data. We can use this to visualize the main instructions within the instructions for our recipes."],"metadata":{"id":"e3h5B1sPsc4_"}},{"cell_type":"code","source":["from wordcloud import WordCloud"],"metadata":{"id":"IzXBI0xg8cPy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#TODO: Word Cloud on 'method' of bbc_df\n"],"metadata":{"id":"YTP6nGHWsgE4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#TODO: Word Cloud on 'title' of bbc_df\n","\n","#plt.subplots(figsize = (26, 12))\n","\n"],"metadata":{"id":"aeuzO53yspcl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Conclusion\n","\n","Data Wrangling and Visualization are the bread and butter of data analysis. This notebook only covers a small slice of things that can be done in Python, which itself is only one tool among hundreds avaliable for this task.\n","\n","We hope this notebook was helpful to you, and please reach out to us if you have any questions!\n","\n","Thanks everyone :)"],"metadata":{"id":"PAObXwnhcVSa"}}]}